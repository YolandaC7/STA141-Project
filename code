# STA141-Project

library(tidyverse)
library(knitr)
library(dplyr)
# Load the data to R
session=list()
for(i in 1:18){
  session[[i]]=readRDS(paste('./Data/session',i,'.rds',sep=''))
}
# Summarize total sessions
n.session = length(session)
# Organize and print the names of each column for new dataframe
meta  = tibble(
  mouse_name = rep('name',n.session),
  date_exp = rep('dt',n.session),
  n_brain_area = rep(0,n.session),
  n_neurons = rep(0,n.session),
  n_trials = rep(0,n.session),
  success_rate = rep(0,n.session)
)

# Using loop, deciding the contents under each columns, including names of types of mouse, the dates when experiment did, the number of used brain areas, and number of relevant neurons, total number of trials, and the success rate. 
for(i in 1:n.session){
  tmp = session[[i]];
  meta[i,1] = tmp$mouse_name;
  meta[i,2] = tmp$date_exp;
  meta[i,3] = length(unique(tmp$brain_area));
  meta[i,4] = dim(tmp$spks[[1]])[1];
  meta[i,5] = length(tmp$feedback_type);
  meta[i,6] = mean(tmp$feedback_type + 1) / 2;
  }

# Using the new number we calculate in the previous step to replace the original number in the data file. 
kable(meta , format = "html", table.attr = "class = 'table table-striped'", digits = 2)

# Indicator for 3rd session
i.s = 3
# Indicator for 1st trial
i.t = 1
# Extract data for spikes from first trial in third session
spk.trial = session[[i.s]]$spks[[i.t]]
# Extract brain area from third session
area = session[[i.s]]$brain_area

# Calculate the total number of spikes for each neuron during first trial 
spk.count = apply(spk.trial,1,sum)
# Calculate the total number of spikes across neurons that live in the same areas
spk.average.tapply = tapply(spk.count, area, mean)
# Using new data about brain area and total number of spikes for each neuron in specific brain area in the third session to form a new dataset
tmp = data.frame(
  area = area,
  spikes = spk.count
)
tmp
# Calculate the average number for spikes by group, area. 
spk.average.dplyr = tmp %>%
  group_by(area) %>%
  summarize(mean = mean(spikes)) 

# Wrapping up the function to average number for spikes in brain areas
average_spike_area = function(i.t,this_session){
  spk.trial = this_session$spks[[i.t]]
  area = this_session$brain_area
  spk.count = apply(spk.trial, 1, sum)
  spk.average.tapply = tapply(spk.count, area, mean)
  return(spk.average.tapply)
  }
# Test the function 
average_spike_area(1, this_session = session[[i.s]])

# Learn the total number of feedback types in the third session
n.trial = length(session[[i.s]]$feedback_type)
# Learn the total number of brain areas in the third session
n.area = length(unique(session[[i.s]]$brain_area))

# Create a data frame that contain the average spike counts for each area, feedback type, two contrasts, and the trial id. 
trial.summary = matrix(nrow = n.trial, ncol = n.area + 1 + 2 + 1)
for(i.t in 1:n.trial){
  trial.summary[i.t,] = c(average_spike_area(i.t,this_session = session[[i.s]]),
                          session[[i.s]]$feedback_type[i.t],
                        session[[i.s]]$contrast_left[i.t],
                        session[[i.s]]$contrast_right[i.s],
                        i.t)
}

# Given name for the new dataset
brain = names(average_spike_area(i.t,this_session = session[[i.s]]))
colnames(trial.summary) = c(brain, 'feedback', 'left contr.','right contr.','id')

# Turning it into a data frame
trial.summary = as_tibble(trial.summary)
trial.summary

# Different brain areas have various specific color in the plot
area.col = rainbow(n = n.area, alpha = 1)
# Crate a blank plot with y-axis ranging from 0.5 to 2.2 and x-axis ranging from 0 to the total number of trials
plot(x = 1,y =0, col = 'white', xlim = c(0,n.trial), ylim = c(0.5,2.2), xlab = "Trials",ylab = "Average spike counts", main = paste("Spikes per area in Session", i.s))

# Using loop, learning correlated number of average spike in total brain areas and fill the number into the plot 
for(i in 1:n.area){
  lines(y = trial.summary[[i]], x =trial.summary$id, col = area.col[i], lty = 2,lwd = 1)
  lines(smooth.spline(trial.summary$id,  trial.summary[[i]]), col=area.col[i], lwd=3)
  }
legend("topright", 
  legend = colnames(trial.summary)[1:n.area], 
  col = area.col, 
  lty = 1, 
  cex = 0.8
)

data2 = data.frame(session = integer(), 
                   trial = integer(), 
                   name = character(),
                   average_spikes = double(), 
                   n.neurons = double(), 
                   feedback = integer())

for (i in 1:length(session)) {
  for (j in 1:length(session[[i]]$spks)) {
    mouse_name = session[[i]]$mouse_name
    spks_trial = session[[i]]$spks[[j]]
    spikes_count = apply(spks_trial, 1, sum)
    avg.spks = mean(spikes_count)
    num_neurons = meta$n_neurons[i]
    feedback_type = session[[i]]$feedback_type[j]
    
    data2 = rbind(data2, data.frame(session = i, trial = j, name = mouse_name, average_spikes = avg.spks, n.neurons = num_neurons, feedback = feedback_type))
  }
}
data2

ggplot(data2, aes(x = session, y = average_spikes)) +
  geom_point() +
  labs(x = "Session", y = "Average Spikes") +
  ggtitle("Average Spikes Across Sessions")

ggplot(data2) +
  geom_point(mapping = aes(x = trial, y = average_spikes), alpha = 0.2) +
  labs(x = "Trial", y = "Average Spikes") +
  ggtitle("Average Spikes Across Trials")

spk.average.dplyr = tmp %>%
  group_by(area) %>%
  summarize(mean = mean(spikes)) 
spk.average.dplyr

ggplot(spk.average.dplyr, aes(x = area , y = mean)) +
  geom_line() +
  geom_point() +
  labs(x = "Brain Area", y = "Average Spikes") +
  ggtitle("Relationship between Average Spikes and Brian Area")

library(ggplot2)
ggplot(meta, aes(x = mouse_name, y = as.numeric(success_rate),col = mouse_name)) +
  geom_boxplot() +
  xlab("Mouse") +
  ylab("Success rate") +
  ggtitle("Success rate by Mouse") 

ggplot(meta, aes(x = mouse_name, y = as.integer(n_brain_area),col = mouse_name)) +
  geom_boxplot() +
  xlab("Mouse") +
  ylab("brain area") +
  ggtitle("Brain area by Mouse") 

ggplot(meta, aes(x = mouse_name, y = as.numeric(n_neurons),col = mouse_name)) +
  geom_boxplot() +
  xlab("Mouse") +
  ylab("number of neurons") +
  ggtitle("number of neurons by Mouse")


ggplot(data2, aes(x = name, y = as.numeric(average_spikes), col = name)) +
  geom_boxplot() +
  xlab("Mouse") +
  ylab("Average number of spikes") +
  ggtitle("Average number of spikes by Mouse")

# Extract data of spikes from Trial 1 in Session 1
spks.trial = session[[1]]$spks[[1]]
# Total number of spikes in Trial 1 of Session 1
total.spikes = apply(spks.trial, 1, sum)
# Average number of spikes per neuron in the Trial 1 of Session 1
(avg.spikes = mean(total.spikes))

# Create dataset for average spikes
data1 = data.frame(session = integer(), 
                   trial = integer(), 
                   average_spikes = double(), 
                   contrast_left = double(), 
                   contrast_right = double(), 
                   n.neurons = double(), 
                   feedback = integer())

for (i in 1:length(session)) {
  for (j in 1:length(session[[i]]$spks)) {
    spks_trial = session[[i]]$spks[[j]]
    spikes_count = apply(spks_trial, 1, sum)
    avg.spks = mean(spikes_count)
    contrast.left = session[[i]]$contrast_left[j]
    contrast.right = session[[i]]$contrast_right[j]
    num_neurons = meta$n_neurons[i]
    feedback_type = session[[i]]$feedback_type[j]
    
    data1 = rbind(data1, data.frame(session = i, trial = j, average_spikes = avg.spks, contrast_left = contrast.left, contrast_right = contrast.right, n.neurons = num_neurons, feedback = feedback_type))
  }
}
data1

library(MASS)
library(caTools)
set.seed(123)
feedback = as.factor(data1$feedback)

# split data
split = sample.split(data1, SplitRatio = 0.80)

train_data = subset(data1, split == TRUE)
test_data = subset(data1, split == FALSE)
model = glm(feedback ~ average_spikes, data = train_data, family = "gaussian")
model
prediction = predict(model, newdata = test_data, type = 'response') 
prediction_class = ifelse(prediction > 0.5, 'Sensitive', 'Not Sensitive')  

# Confusion matrix from logistic
confusion_matrix= table(actual = test_data$feedback, predict = prediction_class, dnn = c('Predicted Direction', 'Feedback'))
confusion_matrix
# test error
misclassification_rate = 1 - sum(diag(confusion_matrix)) / sum(confusion_matrix)
misclassification_rate

cat("Misclassification Error Rate:", misclassification_rate, "\n")

test = list()
for(i in 1:2){
  test[[i]]=readRDS(paste('./test_data/test',i,'.rds',sep=''))
}

test_data_n = data.frame(session = integer(), 
                   trial = integer(), 
                   average_spikes = double(), 
                   contrast_left = double(), 
                   contrast_right = double(), 
                   feedback = integer())

for (i in 1:length(test)) {
  for (j in 1:length(test[[i]]$spks)) {
    spks_trial = test[[i]]$spks[[j]]
    spikes_count = apply(spks_trial, 1, sum)
    avg.spks = mean(spikes_count)
    contrast.left = test[[i]]$contrast_left[j]
    contrast.right = test[[i]]$contrast_right[j]
    feedback_type = test[[i]]$feedback_type[j]
    
    test_data_n = rbind(test_data_n, data.frame(session = i, trial = j, average_spikes = avg.spks, contrast_left = contrast.left, contrast_right = contrast.right, feedback = feedback_type))
  }
}
test_data_n

train_data = subset(data1, split == TRUE)
model_test = glm(feedback ~ average_spikes, data = train_data, family = "gaussian")
model_test
prediction_test = predict(model_test, newdata = test_data_n, type = 'response') 
prediction_class_test = ifelse(prediction_test > 0.5, 'Sensitive', 'Not Sensitive')  

# Confusion matrix from logistic
confusion_matrix_test = table(actual = test_data_n$feedback, predict = prediction_class_test, dnn = c('Predicted Direction', 'Feedback'))
confusion_matrix_test
# test error
misclassification_rate_test = 1 - sum(diag(confusion_matrix)) / sum(confusion_matrix)
misclassification_rate_test

cat("Misclassification Error Rate:", misclassification_rate_test, "\n")

